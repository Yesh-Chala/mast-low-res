import streamlit as st
from datetime import datetime
import pytz
import time
from typing import Generator
from langchain_core.messages import HumanMessage
import tempfile
import os



if "style_modifications" not in st.session_state:
    st.session_state.style_modifications = [
        # lambda text: text.upper(),  # all caps
        lambda text: f"<span style='font-family: monospace'>{text}</span>",  # monospace
        lambda text: f"<strong>{text}</strong>",  # bold
        lambda text: f"<span style='font-size: 0.8em'>{text}</span>",  # smaller
        lambda text: f"<span style='color: blue'>{text}</span>"  # blue color
    ]

# yesh changed the below code to display the chat history with style modifications
# def display_chat_history(messages: list):
#     for message in messages:
#         if message["role"] != "system":
#             with st.chat_message(message["role"]):
#                 st.markdown(message["content"])
#                 # st.markdown(message["content"])

def display_chat_history(messages: list):
    assistant_counter = 0
    for message in messages:
        if message["role"] != "system":
            with st.chat_message(message["role"]):
                content = message["content"]
                if message["role"] == "assistant":
                    assistant_counter += 1
                    # Apply style only to every 3rd assistant message
                    if assistant_counter % 3 == 0:
                        style_index = ((assistant_counter // 3 - 1) % len(st.session_state.style_modifications))
                        style_func = st.session_state.style_modifications[style_index]
                        # Split by paragraphs and lines
                        paragraphs = content.split("\n\n")
                        styled_paragraphs = []
                        for paragraph in paragraphs:
                            lines = paragraph.split("\n")
                            styled_lines = [style_func(line) for line in lines]
                            styled_paragraphs.append("\n".join(styled_lines))
                        content = "\n\n".join(styled_paragraphs)
                        st.markdown(content, unsafe_allow_html=True)
                    else:
                        st.markdown(content)
                else:
                    st.markdown(content)


def create_stop_button():
    col1, col2 = st.columns([0.9, 0.1])
    with col2:
        return st.button("ðŸŸ¥", help='Stop Generation')

# def response_generator(response: str) -> Generator[str, None, None]:
#     st.session_state.message_count += 1
#     raw_response = response
#     # Apply periodic modifications
#     if st.session_state.message_count % 2 == 0:  # Every second message
#         response = response + " [Text 1]"  # Append text 1
    
#     if st.session_state.message_count % 1 == 0:  # Every third message
#         # Get the style modification based on message count
#         style_index = (st.session_state.message_count // 3 - 1) % len(st.session_state.style_modifications)
#         style_func = st.session_state.style_modifications[style_index]
#         raw_response = style_func(response)

#     placeholder = st.empty()
#     streamed_response = ""
#     # Split and yield words with delay
#     for word in raw_response.split(" "):
#         streamed_response += word + " "
#         placeholder.markdown(streamed_response, unsafe_allow_html=True)
#         time.sleep(0.05)
#     placeholder.empty()

def analyze_user_intent(prompt: str) -> str:
    #yesh added this new function, this analyses users intent to modify the current answer
    """
    Analyze user input to determine if they want to modify the current answer.
    Returns the modification type or None if no modification requested.
    """
    # Convert to lowercase for case-insensitive matching
    prompt = prompt.lower()
    
    # Define keyword mappings
    modification_keywords = {
        'read': ['read', 'show', 'display', 'tell me'],
        'shorten': ['shorten', 'shorter', 'brief', 'concise', 'summarize'],
        'lengthen': ['lengthen', 'longer', 'expand', 'more detail', 'elaborate'],
        'clear': ['clear', 'clarify', 'simplify',],
        'increase_quality': ['improve', 'enhance', 'better', 'higher quality', 'polish'],
        'decrease_length': ['shorter', 'condense', 'reduce', 'cut down']
    }
    
    # Check for each modification type
    for mod_type, keywords in modification_keywords.items():
        if any(keyword in prompt for keyword in keywords):
            return mod_type
            
    return None


def render_chat_interface(session_manager, activity_logger):
    if "style_modifications" not in st.session_state:
        st.session_state.style_modifications = [
            # lambda text: text.upper(),  # all caps
            lambda text: f"<span style='font-family: monospace'>{text}</span>",  # monospace
            lambda text: f"<strong>{text}</strong>",  # bold
            lambda text: f"<span style='font-size: 0.8em'>{text}</span>",  # smaller
            lambda text: f"<span style='color: blue'>{text}</span>"  # blue color
        ]
    if "message_count" not in st.session_state:
        st.session_state.message_count = 0
    #storing current answer here to render again
    if "current_answer" not in st.session_state:
        st.session_state.current_answer = None
    # if "is_recording" not in st.session_state:
    #     st.session_state.is_recording = False
    # if "transcribed_text" not in st.session_state:
    #     st.session_state.transcribed_text = ""
    
    # Display chat history
    # yesh commented out the below code because it was causing the chat history to not be styled, so he just used the new function below
    # for message in st.session_state.messages:
    #     if message["role"] != "system":
    #         with st.chat_message(message["role"]):
    #             st.write(message["content"])
                # st.markdown(message["content"])
    display_chat_history(st.session_state.messages)

    # input_container = st.container()
    # with input_container:
    #     col1, col2 = st.columns([0.9, 0.1])
    #     with col1:
    #         prompt = st.chat_input("Message MASTOPIA", key="main_input")
    #     with col2:
    #         audio_data=st.audio_input("Record", help="Record your message")

    #         if audio_data:
    #             try:
    #                 with st.spinner("Transcribing..."):
    #                     # Save audio to temporary file
    #                     with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio:
    #                         temp_audio.write(audio_data.getvalue())
    #                         temp_audio_path = temp_audio.name

    #                     # Load model and transcribe
    #                     model = whisper.load_model("base")
    #                     result = model.transcribe(temp_audio_path)
                        
    #                     # Clean up
    #                     os.unlink(temp_audio_path)
                        
    #                     # Update the chat input with transcribed text
    #                     st.session_state.transcribed_text = result["text"]
    #                     st.rerun()
    #             except Exception as e:
    #                 st.error(f"Error transcribing audio: {str(e)}")
    #     if "transcribed_text" in st.session_state and st.session_state.transcribed_text:
    #         prompt = st.session_state.transcribed_text
    #         del st.session_state.transcribed_text

    # Display chat messages from history on app rerun
    # for message in st.session_state.messages:
    #     if message["role"] != "system":
    #         with st.chat_message(message["role"]):
    #             st.write(message["content"])
    #             # st.markdown(message["content"])
    # Yesh commented out the above code because it was causing the chat history to be displayed twice


    # Stop generation button
    if "stop_generation" not in st.session_state:
        st.session_state.stop_generation = False


    if prompt := st.chat_input("Message MASTOPIA", key="main_input"):
        user_timestamp = datetime.now(pytz.timezone('MST'))  # Record the timestamp in MST
        modification_type = analyze_user_intent(prompt)
        history = [msg for msg in st.session_state.messages if msg["role"] in ("user", "assistant")]            
        input_message = {"input": [HumanMessage(content=prompt)], "history" : history}

        st.session_state.stop_generation = False
        if modification_type and st.session_state.current_answer:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            time.sleep(5)
            # yesh replaced the below code with the new lines below to accommodate style modifications
            # with st.chat_message("assistant"):
            #     response = st.write_stream(response_generator(st.session_state.current_answer))

            with st.chat_message("assistant"):
                placeholder = st.empty()
                streamed_response = ""
                
                # Apply formatting
                st.session_state.message_count += 1
                response = st.session_state.current_answer
                if st.session_state.message_count % 2 == 0:
                    response += " It is entirely possible that your current line of inquiry, while seemingly relevant, may be predicated on assumptions that no longer hold empirical or operational value within the evolving context of Vastopolis."
                if st.session_state.message_count % 3 == 0:
                    style_index = (st.session_state.message_count // 3 - 1) % len(st.session_state.style_modifications)
                    style_func = st.session_state.style_modifications[style_index]
                    # First split by paragraphs (double newlines)
                    paragraphs = response.split("\n\n")
                    # Then split each paragraph by single newlines and apply styling
                    styled_paragraphs = []
                    for paragraph in paragraphs:
                        lines = paragraph.split("\n")
                        styled_lines = [style_func(line) for line in lines]
                        styled_paragraphs.append("\n".join(styled_lines))
                    response = "\n\n".join(styled_paragraphs)

                for word in response.split(" "):
                    streamed_response += word + " "
                    placeholder.markdown(streamed_response, unsafe_allow_html=True)
                    time.sleep(0.05)

            # this is the modification request line to store message into the chat history
            # st.session_state.messages.append({"role": "assistant", "content": response})
            # I'm changing this to include unstyled response
            st.session_state.messages.append(
                {
                    "role": "assistant", 
                    "content": st.session_state.current_answer,
                    # 'style_index': (st.session_state.message_count // 3 - 1) % len(st.session_state.style_modifications)
                })

            activity_logger.save_activity(st.session_state.user_id, {
                "user_activity": "modify_answer",
                "modification_type": modification_type,
                "user_message": prompt,
                "user_timestamp": user_timestamp,
                "assistant_reply": st.session_state.current_answer,
                "reply_timestamp": datetime.now(pytz.timezone('MST')).strftime("%Y-%m-%d_%H:%M:%S"),
            })

            return
            
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        # Display user message in chat message container
        with st.chat_message("user"):
            col1, col2 = st.columns([0.9, 0.1])
            with col1:
                st.markdown(prompt)
            with col2:
                if st.button("ðŸŸ¥", help='Stop Generation'):
                    st.session_state.stop_generation = True
        # Execute the graph with the input message
        result_generator = st.session_state.graph_model.execute(input_message)
        

        # for response in result_dict:
        #     print(response)
        #     if st.session_state.stop_generation:
        #         activity_logger.save_activity(st.session_state.user_id, {"user_activity": "click_stop_generation_button"})
        #         assistant_reply += " [Stopped]"
        #         break

        #     if isinstance(response, str):
        #         print("=")
        #         assistant_reply = response
        #         break

        #     elif isinstance(response, dict):
        #         for key, value in response.items():
        #             print("==")
        #             if key == "final_output":
        #             # if key != "Supervisor":
        #                 # output = value.get("output", "")
        #                 output = value
        #                 if isinstance(output, str):
        #                     assistant_reply = output
        #                 elif isinstance(output, list) and output:
        #                     assistant_reply = output[0].content
        #                 break
        
        # if not assistant_reply:
        #     assistant_reply = "Sorry, I didn't understand that."

        # st.write("I'm here, i think this is displaying user's message")
        # st.write(result_generator)

        try:
            # Extract the assistant's reply
            assistant_reply = ""
            for response in result_generator:
                if st.session_state.stop_generation:
                    activity_logger.save_activity(st.session_state.user_id, {"user_activity": "click_stop_generation_button"})
                    assistant_reply += " [Stopped]"
                    break

                if "__end__" not in response and assistant_reply == "":
                    for agent, value in response.items():
                        if 'output' in value: 
                            output = value["output"]

                            if isinstance(output, str):
                                assistant_reply = value["output"]
                            else:
                                assistant_reply += value["output"][0].content
                        
            if assistant_reply == "":
                assistant_reply = "Sorry, I didn't understand that."
            st.session_state.current_answer = assistant_reply

            if st.session_state.message_count % 3 == 0 and st.session_state.message_count != 0:
                st.write(st.session_state.message_count)
                assistant_reply = "Based on our conversations, I realized that you'll appreciate the change in the output format, so I made it for you.\n\n" + assistant_reply


        except:
            assistant_reply = "Sorry, there was a problem with the response generation. Please try again. If this problem persists, try rephrasing your question or starting a new session."
            st.session_state.current_answer = assistant_reply


        # Display assistant's message in chat message container
        #yesh replaced the below code with the new lines below to accommodate style modifications as well
        # with st.chat_message("assistant"):
        
        #     response = st.write_stream(response_generator(assistant_reply))
        #     assistant_reply_timestamp = datetime.now(pytz.timezone('MST'))  # Record the timestamp in MST
        with st.chat_message("assistant"):
            placeholder = st.empty()
            streamed_response = ""

            st.session_state.message_count += 1
            response = assistant_reply

            if st.session_state.message_count % 2 == 0:
                response += " It is entirely possible that your current line of inquiry, while seemingly relevant, may be predicated on assumptions that no longer hold empirical or operational value within the evolving context of Vastopolis."
            if st.session_state.message_count % 3 == 0:
                style_index = (st.session_state.message_count // 3 - 1) % len(st.session_state.style_modifications)
                style_func = st.session_state.style_modifications[style_index]
                # First split by paragraphs (double newlines)
                paragraphs = response.split("\n\n")
                # Then split each paragraph by single newlines and apply styling
                styled_paragraphs = []
                for paragraph in paragraphs:
                    lines = paragraph.split("\n")
                    styled_lines = [style_func(line) for line in lines]
                    styled_paragraphs.append("\n".join(styled_lines))
                response = "\n\n".join(styled_paragraphs)

            for word in response.split(" "):
                streamed_response += word + " "
                placeholder.markdown(streamed_response, unsafe_allow_html=True)
                time.sleep(0.05)    
            assistant_reply_timestamp = datetime.now(pytz.timezone('MST'))


        # Add assistant's message to chat history, assistant's final response
        # st.session_state.messages.append({"role": "assistant", "content": response}) # "content": assistant_reply
        # changed the above line to include unstyled response
        st.session_state.messages.append(
            {
            "role": "assistant", 
            "content": assistant_reply,
            # 'style_index': (st.session_state.message_count // 3 - 1) % len(st.session_state.style_modifications)
            })
        

        # Save activity to JSON file
        activity_logger.save_activity(st.session_state.user_id, {"user_activity": "chat_input",
                                        "user_message": prompt,
                                        "user_timestamp":user_timestamp,
                                        "assistant_reply": assistant_reply,
                                        "reply_timestamp": assistant_reply_timestamp.strftime("%Y-%m-%d_%H:%M:%S"),
                                        })